"""
File ch√≠nh ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng Chatbot AI
Ch·ª©c nƒÉng: 
- T·∫°o giao di·ªán web v·ªõi Streamlit
- X·ª≠ l√Ω t∆∞∆°ng t√°c chat v·ªõi ng∆∞·ªùi d√πng
- K·∫øt n·ªëi v·ªõi AI model ƒë·ªÉ tr·∫£ l·ªùi
"""

# === IMPORT C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT ===
import streamlit as st  # Th∆∞ vi·ªán t·∫°o giao di·ªán web
from dotenv import load_dotenv  # ƒê·ªçc file .env ch·ª©a API key
from seed_data import seed_pdf_data, get_available_collections  # Ch·ªâ import h√†m x·ª≠ l√Ω PDF
from agent import get_retriever, get_llm_and_agent, determine_collection
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
import os

# === THI·∫æT L·∫¨P GIAO DI·ªÜN TRANG WEB ===
def setup_page():
    """
    C·∫•u h√¨nh trang web c∆° b·∫£n
    """
    st.set_page_config(
        page_title="AI Assistant",  # Ti√™u ƒë·ªÅ tab tr√¨nh duy·ªát
        page_icon="üí¨",  # Icon tab
        layout="wide"  # Giao di·ªán r·ªông
    )

# === KH·ªûI T·∫†O ·ª®NG D·ª§NG ===
def initialize_app():
    """
    Kh·ªüi t·∫°o c√°c c√†i ƒë·∫∑t c·∫ßn thi·∫øt:
    - ƒê·ªçc file .env ch·ª©a API key
    - C·∫•u h√¨nh trang web
    """
    load_dotenv()  # ƒê·ªçc API key t·ª´ file .env
    setup_page()  # Thi·∫øt l·∫≠p giao di·ªán

# === THANH C√îNG C·ª§ B√äN TR√ÅI ===
def setup_sidebar():
    """
    T·∫°o thanh c√¥ng c·ª• b√™n tr√°i v·ªõi c√°c t√πy ch·ªçn
    """
    with st.sidebar:
        st.title("‚öôÔ∏è C·∫•u h√¨nh")
        
        # Ph·∫ßn 1: Ch·ªçn Embeddings Model
        st.header("üî§ Embeddings Model")
        embeddings_choice = st.radio(
            "Ch·ªçn Embeddings Model:",
            ["HuggingFace"]
        )
        use_huggingface = (embeddings_choice == "HuggingFace")
        
        # Ph·∫ßn 2: C·∫•u h√¨nh Data
        st.header("üìö Ngu·ªìn d·ªØ li·ªáu")
        data_source = st.radio(
            "Ch·ªçn ngu·ªìn d·ªØ li·ªáu:",
            ["File PDF Local"]
        )
        
        if data_source == "File PDF Local":
            handle_local_file(use_huggingface)
            
        # Hi·ªÉn th·ªã c√°c collection ƒëang c√≥
        st.header("üîç Collections hi·ªán c√≥")
        collections = get_available_collections("chroma_db")
        if collections:
            st.write("C√°c nh√≥m d·ªØ li·ªáu:")
            for col in collections:
                st.info(f"üìö {col}")
        else:
            st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c t·∫£i l√™n")
        
        # Ph·∫ßn 3: Model AI - Removed model choice since we're only using Groq
        st.header("ü§ñ Model AI")
        st.info("S·ª≠ d·ª•ng Groq AI (deepseek-r1-distill-llama-70b)")
        model_choice = "groq"
        
        return model_choice

def handle_local_file(use_huggingface: bool):
    """
    X·ª≠ l√Ω khi ng∆∞·ªùi d√πng ch·ªçn t·∫£i file PDF
    """
    st.markdown("##### Th√¥ng tin v·ªÅ th∆∞ m·ª•c PDF")
    st.info("Th∆∞ m·ª•c ch·ª©a PDF: E:/WORK/project/chatbot_RAG/data/pdf")
    
    if st.button("T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu PDF"):
        with st.spinner("ƒêang x·ª≠ l√Ω c√°c file PDF..."):
            try:
                persist_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "chroma_db")
                seed_pdf_data(
                    pdf_directory="E:/WORK/project/chatbot_RAG/data/pdf",
                    persist_directory=persist_dir
                )
                st.success("ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng c√°c file PDF!")
            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω PDF: {str(e)}")

# === GIAO DI·ªÜN CHAT CH√çNH ===
def setup_chat_interface(model_choice):
    st.title("üí¨ AI Assistant")
    
    # Caption ƒë·ªông theo model
    st.caption("üöÄ Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† Groq AI")
    
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"}
        ]
        msgs.add_ai_message("T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?")

    for msg in st.session_state.messages:
        role = "assistant" if msg["role"] == "assistant" else "human"
        st.chat_message(role).write(msg["content"])

    return msgs

# === X·ª¨ L√ù TIN NH·∫ÆN NG∆Ø·ªúI D√ôNG ===
def handle_user_input(msgs, agent_executor, retriever):
    """
    X·ª≠ l√Ω khi ng∆∞·ªùi d√πng g·ª≠i tin nh·∫Øn
    """
    if prompt := st.chat_input("H√£y h·ªèi t√¥i v·ªÅ th·ªß t·ª•c h√†nh ch√≠nh c√¥ng"):
        st.session_state.messages.append({"role": "human", "content": prompt})
        st.chat_message("human").write(prompt)
        msgs.add_user_message(prompt)

        with st.chat_message("assistant"):
            with st.expander("üîç K·∫øt qu·∫£ t√¨m ki·∫øm"):
                collection = determine_collection(prompt)
                st.info(f"ƒêang t√¨m trong nh√≥m: {collection}")
                
                # S·ª≠ d·ª•ng invoke thay v√¨ get_relevant_documents
                relevant_docs = retriever.invoke(prompt)
                
                for i, doc in enumerate(relevant_docs, 1):
                    st.markdown(f"""
                    **K·∫øt qu·∫£ {i}**
                    - Ngu·ªìn: {doc.metadata.get('source', 'Kh√¥ng r√µ')}
                    - N·ªôi dung: {doc.page_content[:200]}...
                    """)
            
            st_callback = StreamlitCallbackHandler(st.container())
            
            # L·∫•y l·ªãch s·ª≠ chat
            chat_history = [
                {"role": msg["role"], "content": msg["content"]}
                for msg in st.session_state.messages[:-1]
            ]

            # G·ªçi AI x·ª≠ l√Ω
            response = agent_executor.invoke(
                {
                    "input": prompt,
                    "chat_history": chat_history
                },
                {"callbacks": [st_callback]}
            )

            # L∆∞u v√† hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
            output = response["output"]
            st.session_state.messages.append({"role": "assistant", "content": output})
            msgs.add_ai_message(output)
            st.write(output)

# === H√ÄM CH√çNH ===
def main():
    """
    H√†m ch√≠nh ƒëi·ªÅu khi·ªÉn lu·ªìng ch∆∞∆°ng tr√¨nh
    """
    initialize_app()
    model_choice = setup_sidebar()
    msgs = setup_chat_interface(model_choice)
    
    # Kh·ªüi t·∫°o retriever v·ªõi ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
    persist_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "chroma_db")
    retriever = get_retriever(persist_dir)
    agent_executor = get_llm_and_agent(retriever)
    
    handle_user_input(msgs, agent_executor, retriever)

# Ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    main()
